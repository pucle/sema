"""
CODE CHáº Y LOCAL - HOÃ€N TOÃ€N MIá»„N PHÃ
API Key chá»‰ dÃ¹ng Ä‘á»ƒ táº£i model láº§n Ä‘áº§u, sau Ä‘Ã³ cháº¡y offline Ä‘Æ°á»£c
"""

from inference import InferencePipeline
from inference.core.interfaces.camera.entities import VideoFrame
import cv2
import time
import onnxruntime as ort
import os

# MONKEY PATCH: Force OpenVINO to use GPU
OriginalSession = ort.InferenceSession

class PatchedSession(OriginalSession):
    def __init__(self, path_or_bytes, **kwargs):
        providers = kwargs.get("providers", [])
        if not providers:
            # inference might set check providers later or pass them differently
            pass
        
        # Check if we should inject OpenVINO options
        new_providers = []
        for p in providers:
            if p == "OpenVINOExecutionProvider" or (isinstance(p, tuple) and p[0] == "OpenVINOExecutionProvider"):
                print("DEBUG: Patching OpenVINO to use GPU_FP16")
                # Use tuple format (name, options)
                new_providers.append(("OpenVINOExecutionProvider", {"device_type": "GPU_FP16"}))
            else:
                new_providers.append(p)
        
        if new_providers:
            kwargs["providers"] = new_providers
            
        super().__init__(path_or_bytes, **kwargs)

ort.InferenceSession = PatchedSession

# Check available providers
print(f"DEBUG: ONNX Runtime Providers: {ort.get_available_providers()}")
# Force inference lib to select OpenVINO
if "OpenVINOExecutionProvider" in ort.get_available_providers():
    print("DEBUG: OpenVINO detected. Setting env var.")
    os.environ["ROBOFLOW_INFERENCE_DEVICE"] = "openvino"


class LocalVideoProcessor:
    def __init__(self):
        self.frame_count = 0
        self.start_time = time.time()
        self.detection_count = 0
        
    def process_predictions(self, predictions: dict, video_frame: VideoFrame):
        """Xá»­ lÃ½ predictions tá»« model - CHáº Y HOÃ€N TOÃ€N LOCAL"""
        
        self.frame_count += 1
        frame = video_frame.image.copy()
        
        # TÃ­nh FPS
        elapsed = time.time() - self.start_time
        fps = self.frame_count / elapsed if elapsed > 0 else 0
        
        # Váº½ predictions lÃªn frame
        if predictions and "predictions" in predictions:
            for pred in predictions["predictions"]:
                self.detection_count += 1
                
                # TÃ­nh toÃ¡n bounding box
                x = int(pred["x"] - pred["width"] / 2)
                y = int(pred["y"] - pred["height"] / 2)
                w = int(pred["width"])
                h = int(pred["height"])
                confidence = pred["confidence"]
                class_name = pred["class"]
                
                # Váº½ box mÃ u xanh lÃ¡
                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                
                # Váº½ label vá»›i background
                label = f"{class_name}: {confidence:.2%}"
                (label_w, label_h), _ = cv2.getTextSize(
                    label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
                )
                cv2.rectangle(frame, (x, y - label_h - 10), 
                            (x + label_w, y), (0, 255, 0), -1)
                cv2.putText(frame, label, (x, y - 5),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
        
        # Hiá»ƒn thá»‹ thÃ´ng tin FPS vÃ  detections
        info_text = f"FPS: {fps:.1f} | Frames: {self.frame_count} | Detections: {len(predictions.get('predictions', []))}"
        cv2.putText(frame, info_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        
        # Hiá»ƒn thá»‹ frame
        cv2.imshow("Roboflow Local Detection", frame)
        
        # Nháº¥n 'q' Ä‘á»ƒ thoÃ¡t
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            print(f"\nâœ… ÄÃ£ xá»­ lÃ½ {self.frame_count} frames")
            print(f"ğŸ“Š Tá»•ng detections: {self.detection_count}")
            print(f"âš¡ FPS trung bÃ¬nh: {fps:.2f}")
            pipeline.terminate()
        
        # In log má»—i 30 frames
        if self.frame_count % 30 == 0:
            print(f"Frame {self.frame_count} | FPS: {fps:.1f} | "
                  f"Detections: {len(predictions.get('predictions', []))}")

# Khá»Ÿi táº¡o processor
processor = LocalVideoProcessor()

# QUAN TRá»ŒNG: TÃ¬m workspace_name vÃ  model_id cá»§a báº¡n
# Truy cáº­p: https://app.roboflow.com/
# Chá»n project -> Settings -> copy "workspace/project/version"
# VÃ­ dá»¥: "trai26/vehicle-detection/3"

print("="*60)
print("ğŸš€ ROBOFLOW LOCAL INFERENCE - MIá»„N PHÃ 100%")
print("="*60)
print("ğŸ“Œ API Key chá»‰ dÃ¹ng Ä‘á»ƒ táº£i model láº§n Ä‘áº§u")
print("ğŸ“Œ Sau Ä‘Ã³ cháº¡y hoÃ n toÃ n LOCAL, khÃ´ng tá»‘n credit")
print("ğŸ“Œ Nháº¥n 'q' Ä‘á»ƒ thoÃ¡t")
print("="*60)

# Khá»Ÿi táº¡o pipeline - CHáº Y LOCAL
pipeline = InferencePipeline.init(
    api_key="ylFu6Gi5msSoDxbPC9Sl",  # API key cá»§a báº¡n
    model_id="semaphore-dataset-1wlaa/1",  # âš ï¸ THAY Äá»”I: workspace/project/version
    video_reference=0,  # 0 = webcam, hoáº·c Ä‘Æ°á»ng dáº«n video
    max_fps=30,  # Giá»›i háº¡n FPS Ä‘á»ƒ trÃ¡nh quÃ¡ táº£i
    on_prediction=processor.process_predictions,
)

try:
    pipeline.start()
    pipeline.join()
except KeyboardInterrupt:
    print("\nâ›” Dá»«ng bá»Ÿi ngÆ°á»i dÃ¹ng")
finally:
    cv2.destroyAllWindows()
    print("\nâœ… ÄÃ£ Ä‘Ã³ng táº¥t cáº£ cá»­a sá»•")